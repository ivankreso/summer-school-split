{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation\n",
    "\n",
    "In this exercise we will implement a convolutional neural network for semantic segmentation.\n",
    "The goal of semantic segmentation is to classify the image on the pixel level, for each pixel\n",
    "we want to determine the class of the object which it belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "num_epochs = 50\n",
    "batch_size = 10\n",
    "num_classes = Dataset.num_classes\n",
    "\n",
    "# learning_rate = 5e-4\n",
    "# learning_rate = 1e-2\n",
    "learning_rate = 1e-3\n",
    "decay_power = 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_decay = 1e-4\n",
    "reg_func = tf.contrib.layers.l2_regularizer(weight_decay)\n",
    "\n",
    "# need this placeholder for bach norm\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "bn_params = {\n",
    "  # Decay for the moving averages.\n",
    "  'momentum': 0.9,\n",
    "  # epsilon to prevent 0s in variance.\n",
    "  'epsilon': 1e-5,\n",
    "  # fused must be false if BN is frozen\n",
    "  'fused': True,\n",
    "  'training': is_training\n",
    "}\n",
    "\n",
    "\n",
    "def conv_22(x, num_maps, k=3, activation=tf.nn.relu):\n",
    "  return tf.layers.conv2d(x, num_maps, k, activation=activation, padding='same')\n",
    "def conv(x, num_maps, k=3):\n",
    "  x = tf.layers.conv2d(x, num_maps, k, use_bias=False,\n",
    "    kernel_regularizer=tf.contrib.layers.l2_regularizer(weight_decay), padding='same')\n",
    "  x = tf.layers.batch_normalization(x, training=is_training)\n",
    "  return tf.nn.relu(x)\n",
    "\n",
    "def pool(x):\n",
    "  # return tf.layers.average_pooling2d(x, 2, 2, 'same')\n",
    "  return tf.layers.max_pooling2d(x, 2, 2, 'same')\n",
    "\n",
    "\n",
    "def build_model1(x):\n",
    "  # input_size = tf.shape(x)[height_dim:height_dim+2]\n",
    "  input_size = x.get_shape().as_list()[1:3]\n",
    "  print(input_size)\n",
    "  x = conv(x, 32, 3)\n",
    "  x = pool(x)\n",
    "  x = conv(x, 64, 3)\n",
    "  x = pool(x)\n",
    "  x = conv(x, 128, 3)\n",
    "  x = pool(x)\n",
    "  x = conv(x, 128, 3)\n",
    "  # x = pool(x)\n",
    "  # x = conv(x, 64, 3)\n",
    "  # logits = conv(x, num_classes, 3, activation=None)\n",
    "  logits = tf.layers.conv2d(x, num_classes, 1, padding='same')\n",
    "  \n",
    "  logits = tf.image.resize_bilinear(logits, input_size, name='upsample_logits')\n",
    "  return logits\n",
    "\n",
    "def upsample(x, skip, num_maps):\n",
    "  skip_size = skip.get_shape().as_list()[1:3]\n",
    "  x = tf.image.resize_bilinear(x, skip_size)\n",
    "  x = tf.concat([x, skip], 3)\n",
    "  return conv(x, num_maps)\n",
    "\n",
    "\n",
    "def build_model(x, num_classes):\n",
    "  # input_size = tf.shape(x)[height_dim:height_dim+2]\n",
    "  input_size = x.get_shape().as_list()[1:3]\n",
    "  maps = [32, 64, 128, 256, 128]\n",
    "  # maps = [64, 128, 256, 256]\n",
    "  skip_layers = []\n",
    "  x = conv(x, maps[0], k=5)\n",
    "  # x = conv(x, maps[0])\n",
    "  # skip_layers.append(x)\n",
    "  x = pool(x)\n",
    "  x = conv(x, maps[1])\n",
    "  x = conv(x, maps[1])\n",
    "  # skip_layers.append(x)\n",
    "  x = pool(x)\n",
    "  x = conv(x, maps[2])\n",
    "  x = conv(x, maps[2])\n",
    "  # skip_layers.append(x)\n",
    "  x = pool(x)\n",
    "  x = conv(x, maps[3])\n",
    "  x = conv(x, maps[3])\n",
    "  skip_layers.append(x)\n",
    "  x = pool(x)\n",
    "  x = conv(x, maps[4])\n",
    "  x = conv(x, maps[4])\n",
    "  # x = conv(x, maps[3])\n",
    "  # skip_layers.append(x)  \n",
    "  # x = pool(x)\n",
    "  # x = conv(x, maps[4])\n",
    "\n",
    "  # 36 without\n",
    "  for i, skip in reversed(list(enumerate(skip_layers))):\n",
    "    print(i, x, '\\n', skip)\n",
    "    x = upsample(x, skip, maps[i])\n",
    "\n",
    "  # x = pool(x)\n",
    "  # x = conv(x, 64, 3)\n",
    "  # logits = conv(x, num_classes, 3, activation=None)\n",
    "  logits = tf.layers.conv2d(x, num_classes, 1, padding='same')\n",
    "  \n",
    "  logits = tf.image.resize_bilinear(logits, input_size, name='upsample_logits')\n",
    "  return logits, is_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Tensor(\"Relu_8:0\", shape=(?, 10, 24, 128), dtype=float32) \n",
      " Tensor(\"Relu_6:0\", shape=(?, 20, 48, 256), dtype=float32)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'build_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-204185088070>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'build_loss' is not defined"
     ]
    }
   ],
   "source": [
    "train_data = Dataset('train', batch_size)\n",
    "val_data = Dataset('val', batch_size, shuffle=False)\n",
    "\n",
    "height = train_data.height\n",
    "width = train_data.width\n",
    "channels = train_data.channels\n",
    "# x = tf.placeholder(tf.float32, shape=(batch_size, height, width, channels))\n",
    "# y = tf.placeholder(tf.int32, shape=(batch_size, height, width))\n",
    "x = tf.placeholder(tf.float32, shape=(None, height, width, channels))\n",
    "y = tf.placeholder(tf.int32, shape=(None, height, width))\n",
    "\n",
    "logits, is_training = build_model(x, num_classes)\n",
    "loss, logits_vec, y_vec = build_loss(logits, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
